import pandas as pd
import os

# 나무위키 등을 직접 조사하여, 일부 체인점 매장들을 모아두었습니다 -> chain_list
# 입력값으로 매장 이름을 받아, 프랜차이즈 체인 여부와 레귤러 체인 여부를 확인합니다.
# 모든 프랜차이즈 체인은 공정거래위원회의 정보공개서를 참고하였기 때문에 거의 모든 프랜차이즈 체인 매장을 확인할 수 있습니다.
# 하지만 레귤러 체인은 직접 조사하였기 때문에, 전체 레귤레 체인 매장의 일부만을 반영하고 있으니 참고 바랍니다.

chain_list = [
    "던킨도너츠", "맥도날드", "모스버거", "버거킹", "써브웨이", "쉐이크 쉑", "스테프 핫도그", "자니로켓", "쉐이크쉑", "파이브가이즈", "스타벅스", "라그릴리아", "SPC",
    "타코벨", "퀴즈노스", "크리스피 크림 도넛", "파파이스", "판다 익스프레스", "KFC", "파이브가이즈",
    "봉추찜닭", "투다리", "싸움의 고수", "쉐프의 부대찌개", "이바돔 감자탕", "자연별곡", "채선당", "오모가리 김치찌개",
    "신의주 찹쌀순대", "신선설농탕", "남다른감자탕", "홍익돈까스", "담소 소사골순대, 육개장", "불고기브라더스",
    "명동칼국수", "조마루 감자탕", "큰맘할매순대국", "역전할머니맥주", "맛나감자탕", "더하고부대찌개",
    "매드포갈릭", "아웃백스테이크하우스", "빕스(VIPS)", "애슐리", "한스델리", "베니건스", "TGI Fridays", "텍사스 로드하우스",
    "라라코스트", "올리앤", "파리바게뜨", "뚜레쥬르", "코코로벤또", "코코이찌방야", "사보텐", "스시990", "벤또랑", "하루야",
    "하코야", "멘무샤", "홈벤토", "미소야", "아비꼬카레", "오니기리와 이규동", "겐로쿠우동", "이자와", "멘무샤",
    "정성본 샤브수끼 칼국수", "오므토 토마토", "스시노백쉐프", "고씨네", "하루엔소쿠", "쿠우쿠우", "미카도스시",
    "만타스시31", "코바코", "무모한초밥", "상무초밥", "황궁쟁반짜장", "이비가 짬뽕", "홍짜장", "짬뽕타임", "교동짬뽕",
    "중화가정", "티원", "도원스타일", "몽중헌", "메이탄", "꽁시면관", "감탄떡볶이", "고봉민김밥人", "국대떡볶이",
    "국수나무", "김밥천국", "바푸리", "신떡", "아딸", "죠스떡볶이", "틈새라면", "황떡", "얌샘", "떡볶이 창고", "두끼",
    "동대문 엽기떡볶이", "김밥나라", "김가네", "싸다김밥", "종로김밥", "포마토김밥", "수유리우동집", "미아리우동", "길동우동",
    "먹깨비김밥", "깨돌이김밥", "마포만두", "공수간", "용우동", "북촌손만두", "국대떡볶이", "김밥천국", "뉴욕버거", "다운타우너",
    "도니버거", "마포만두", "맘스터치", "롯데리아", "밸런스버거", "아메리카나", "죠스떡볶이", "한솥", "BHC", "노브랜드 버거",
    "버거헌터", "종로김밥", "김가네", "길동우동", "미아리우동", "수유리우동집", "에그몬", "프랭크버거", "토다이", "드마리스",
    "쿠우쿠우", "이디야", "카페베내", "할리스", "탐앤탐스", "투썸플레이스", "엔제리너스", "폴 바셋", "빽다방", "카페 드롭탑",
    "카페 띠아모", "요거프레소", "더카페", "커피에반하다", "커피베이", "메가MGC커피", "컴포즈커피", "더벤티", "더리터", "엔제리너스 커피",
    "감성커피", "하삼동커피", "텐퍼센트커피", "카페봄봄", "카페051", "어벤더치커피", "하이오커피", "디저트39", "떼루와",
    "랑데자뷰", "벤티프레소커피", "킹프레소", "토프레소", "테라로사", "카페게이트", "커피사피엔스", "카페코지", "스타벅스",
    "일리카페", "파스쿠찌", "블루보틀", "커피빈", "팀홀튼", "BBQ치킨", "BHC", "교촌치킨", "처갓집 양념치킨", "네네치킨",
    "굽네치킨", "페리카나", "멕시카나", "호식이 두마리치킨", "푸라닭치킨", "가마치통닭", "또래오래", "지코바치킨", "60계",
    "노랑통닭", "자담치킨", "또봉이통닭", "치킨플러스", "티바두마리치킨", "맥시칸치킨", "박군치킨", "펀비어킹", "부어치킨",
    "땅땅치킨", "바른치킨", "치킨마루", "훌랄라 참숯바베큐치킨", "코리엔탈 깻잎두마리치킨", "신통치킨", "후라이드참잘하는집",
    "순살만공격", "돈치킨", "누구나홀딱반한닭", "치킨신드롬", "깐부치킨", "치킨더홈", "치킨매니아", "투존치킨", "아라치 치킨",
    "호치킨", "보드람치킨", "알통떡강정", "치요남치킨", "본스치킨", "불로만치킨바베큐", "오븐마루", "맛닭꼬", "오븐에 꾸운 닭",
    "오븐에 빠진 닭", "충만치킨", "디디치킨", "가마로강정", "코리안바베큐", "장모님치킨", "기영이 숯불 두마리치킨", "구두로통닭",
    "오태식해바라기치킨", "이춘봉인생치킨", "둘둘치킨", "DK동키치킨", "다사랑치킨", "썬더치킨", "동근이숯불두마리치킨",
    "홍콩반점0410", "해물떡찜0410", "새마을식당", "역전우동0410", "백종원의 원조쌈밥집", "한신포차", "본가", "새마을식당",
    "미정국수0410", "백스비어", "돌배기집", "백철판0410", "롤링파스타", "인생설렁탕", "리춘시장", "성성식당", "막이오름",
    "연돈볼카츠", "빽보이피자", "고투웍", "홍콩분식", "놀부 보쌈족발", "놀부 부대찌개", "놀부 항아리갈비", "놀부옛날통닭",
    "놀부 유황오리진흙구이", "담다", "만면희색", "돈까스퐁당떡볶이 공수간", "쫄면주는 삼겹본능", "흥부찜닭", "직화고기비빔밥 호반식",
    "놀부김치찜", "오불장군", "김치피자탕수육본능", "돈까스본능", "탕수육 본능", "본죽", "본비빔밥", "본죽&비빔밥 카페", "본도시락",
    "본설렁탕", "본우리반상", "더플레이스", "제일제면소", "CJ푸드월드", "엔그릴", "한쿡", "더플레이스다이닝", "N버거",
    "N테라스", "N스위트", "N스위트바", "더스테이크하우스", "TGI Fridays", "빌라드 샬롯", "더 푸드 하우스", "강다짐", "설어정", "명랑핫도그",
    "밀숲", "한소반", "한소반탕마을", "한소반쭈꾸미", "수돈재감자탕", "서가앤쿡", "토끼정", "숨쉬는 순두부", "천하대창군", "미즈컨테이너(Mies Container)",
    "청년다방", "파란만잔", "은화수식당", "치치", "솔솥", "무궁반점", "애슐리", "자연별곡", "피자몰", "로운 샤브샤브",
    "노티드", "리틀넥", "호족반", "클랩 피자", "웍셔너리", "키마스시", "오픈엔드", "애니오케이션 카페", "베이커리 블레어", "미뉴트 빠삐용",
    "우설화", "천지연", "송도갈비", "서현궁", "동백궁", "산삼청각", "청담본갈비", "소나무향기", "송도불고기",
    "한판등심", "자작나무갈비", "돈블랑", "서현돼지", "긴자", "긴자 블루 청담", "일본요리 모슬포", "취홍",
    "하인선생", "한옥 베이커리 카페", "바다쏭 카페&베이커리", "블루커피", "블루가든", "델리봉봉", "더: 봉팡",
    "SFG 푸드빌리지", "SFG 푸드파크", "SFG 마켓", "노브랜드 버거", "노브랜드 피자", "보노보노", "데블스도어", "베키아에누보", "스무디킹", "오슬로", "슈퍼두퍼", "원조큰맘할매순대국", "족발상회", "그램그램",
    "루고", "더카페", "페르케노", "리미니", "후원", "테루", "반궁", "아시아문", "다구오", "스테이크어스"

]


def remove_last_word_if_endswith_jum(store_name):
    words = store_name.split()
    if len(words) > 1 and words[-1].endswith("점"):
        return " ".join(words[:-1])
    return store_name


def check_franchise(store_name):

    directory = os.path.dirname(os.path.abspath(__file__))
    csv_file_path = os.path.join(directory, 'data/', "franchise.csv")

    df = pd.read_csv(csv_file_path, encoding='utf-8-sig')

    store_name = remove_last_word_if_endswith_jum(
        store_name)

    return df['영업표지'].replace(" ", "").str.contains(store_name.lower().replace(" ", ""), na=False).sum() > 0


def check_franchise_list(crawled_data):

    directory = os.path.dirname(os.path.abspath(__file__))
    csv_file_path = os.path.join(directory, 'data/', "franchise.csv")

    df = pd.read_csv(csv_file_path, encoding='utf-8-sig')
    franchise_names = df['영업표지'].str.replace(" ", "").str.lower()
    chain_names = [x.replace(" ", "").lower() for x in chain_list]

    crawled_store_name = crawled_data["name"].apply(
        remove_last_word_if_endswith_jum)
    crawled_store_name = crawled_store_name.str.lower()

    is_franchise = [any(store in franchise for franchise in franchise_names)
                    for store in crawled_store_name]

    is_chain = [any(store in chain for chain in chain_names)
                for store in crawled_store_name]

    result = [a or b for a, b in zip(is_franchise, is_chain)]

    return result


# if __name__ == "__main__":
#     df = pd.DataFrame([{"name": "C27"}])
#     print(check_franchise_list(df))
