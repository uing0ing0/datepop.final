{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, StaleElementReferenceException\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from shapely.geometry import Point\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "\n",
    "from load_bluer import load_bluer\n",
    "from load_hotspots import load_hotspots\n",
    "from haversine import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['store_id', 'name', 'category', 'is_food', 'new_store', 'instagram_link', 'instagram_post', 'instagram_follower', 'hot_spot',\n",
    "           'visitor_review_count', 'blog_review_count', 'distance_from_subway', 'on_tv', 'parking_available', 'no_kids', 'pet_available', \n",
    "           'seoul_michelin', 'age-2030', 'gender-balance', 'on_blue_ribbon', 'image_urls', 'address', 'phone', 'gps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatePopCrawler:\n",
    "    def __init__(self, location, keyword, hotspots, is_food, crawl_new, blue_ribbon):\n",
    "        self.location = location # 크롤링 지역\n",
    "        self.keyword = keyword # 크롤링 키워드\n",
    "        self.search_word = location + \" \" + keyword # 크롤링 검색어\n",
    "\n",
    "        self.hotspots = hotspots # hotspots 정보, 나중에 location 값에 따라서 자동으로 해당 지역의 hotspot 정보를 불러오도록 수정 필요\n",
    "        self.crawl_new = crawl_new # 신규매장 크롤링 여부\n",
    "        self.blue_ribbon = blue_ribbon # location에 대한 블루리본서베이 매장 정보 리스트\n",
    "\n",
    "        self.is_food = is_food # \"맛집\" 키워드 크롤링인지\n",
    "\n",
    "        self.data = pd.DataFrame(columns=columns)\n",
    "\n",
    "        # Iframe 전환용 xpath\n",
    "        self.search_iframe = \"\"\"//*[@id=\"searchIframe\"]\"\"\"\n",
    "        self.entry_iframe = \"\"\"//*[@id=\"entryIframe\"]\"\"\"\n",
    "        self.empty_searchIframe = \"\"\"//*[@id=\"_pcmap_list_scroll_container\"]\"\"\"\n",
    "        self.empty_entryIframe = \"\"\"//*[@id=\"app-root\"]\"\"\"\n",
    "        self.empty_root = \"\"\"//*[@id=\"root\"]\"\"\"\n",
    "        \n",
    "        # 한 매장에 대한 크롤링값 저장\n",
    "        self.store_dict = None\n",
    "\n",
    "        # Chrome driver 세팅\n",
    "        self.driver = self.init_driver()\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "\n",
    "    # 크롬 드라이버 설정\n",
    "    def init_driver(self):\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"--enable-logging\")\n",
    "        options.add_argument(\"--v=1\")  # 로그 레벨 설정\n",
    "\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(\"https://map.naver.com/\")\n",
    "\n",
    "        driver.execute_script(\"window.open('');\")\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        return driver\n",
    "\n",
    "    # 검색어를 input field에 입력 후 클릭\n",
    "    def search_keyword(self):\n",
    "        self.wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, self.empty_root)))\n",
    "\n",
    "        css_selector = \".input_search\"\n",
    "        elem = self.wait.until(EC.presence_of_element_located(\n",
    "            (By.CSS_SELECTOR, css_selector)))\n",
    "\n",
    "        elem.send_keys(self.search_word)\n",
    "        time.sleep(1)\n",
    "        elem.send_keys(Keys.RETURN)\n",
    "\n",
    "    # 한 매장의 크롤링 정보를 저장하는 변수 초기화\n",
    "    def init_dictionary(self):\n",
    "        self.store_dict = {\n",
    "            \"store_id\": None,\n",
    "            \"name\": \"\",\n",
    "            \"category\": \"\",\n",
    "            \"is_food\": self.is_food,\n",
    "            \"new_store\": self.crawl_new,\n",
    "            \"instagram_link\": None,\n",
    "            \"instagram_post\": None,\n",
    "            \"instagram_follower\": None,\n",
    "            \"hot_spot\": False,\n",
    "            \"visitor_review_count\": 0,\n",
    "            \"blog_review_count\": 0,\n",
    "            \"distance_from_subway\": None,\n",
    "            \"on_tv\": False,\n",
    "            \"parking_available\": False,\n",
    "            \"no_kids\": False,\n",
    "            \"pet_available\": False,\n",
    "            \"seoul_michelin\": False,\n",
    "            \"age-2030\": None,\n",
    "            \"gender-balance\": None,\n",
    "            \"on_blue_ribbon\": None,\n",
    "            \"image_urls\": [],\n",
    "            \"address\": None,\n",
    "            \"phone\": None,\n",
    "            \"gps\": {\n",
    "                \"latitude\": None,\n",
    "                \"longitude\": None,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # \"새로오픈\" option 클릭\n",
    "    def click_new_option(self):\n",
    "        time.sleep(1)\n",
    "        self.move_to_search_iframe()\n",
    "        # \"더보기\" 버튼 클릭\n",
    "        more_xpath = \"\"\"//a[span[contains(text(),'더보기')]]\"\"\"\n",
    "        more_button = self.wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, more_xpath)))\n",
    "        self.driver.execute_script(\"arguments[0].click()\", more_button)\n",
    "        # \"새로오픈\" 버튼 클릭\n",
    "        new_xpath = \"\"\"//a[contains(text(),'새로오픈')]\"\"\"\n",
    "        new_button = self.wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, new_xpath)))\n",
    "        self.driver.execute_script(\"arguments[0].click()\", new_button)\n",
    "\n",
    "    # 한 매장에 대한 페이지 열기\n",
    "    def get_into_store(self, index):\n",
    "        # 매장의 정보를 저장할 저장할 dictionay 변수 초기화\n",
    "        self.init_dictionary()\n",
    "        # 매장 목록이 있는 search Iframe으로 이동\n",
    "        self.move_to_search_iframe()\n",
    "\n",
    "        # 현재 페이지의 index번째 매장 클릭\n",
    "        store_xpath = f\"\"\"//*[@id=\"_pcmap_list_scroll_container\"]/ul/li[{\n",
    "            index}]//a[.//div[contains(@class, 'place_bluelink')]]\"\"\"\n",
    "        elem = self.wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, store_xpath)))\n",
    "        time.sleep(2)\n",
    "        self.driver.execute_script(\"arguments[0].scrollIntoView(true);\", elem)\n",
    "        self.driver.execute_script(\"arguments[0].click()\", elem)\n",
    "\n",
    "        # entry Iframe에 접근하기위해 상위 frame으로 이동\n",
    "        time.sleep(1)\n",
    "        self.driver.switch_to.default_content()\n",
    "        self.wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, self.empty_root)))\n",
    "        self.driver.find_element(By.XPATH, self.empty_root)\n",
    "\n",
    "        # 매장 정보가 있는 entry Iframe으로 이동\n",
    "        self.wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, self.entry_iframe)))\n",
    "        iframe_element = self.driver.find_element(By.XPATH, self.entry_iframe)\n",
    "        ## entry Iframe으로 실제로 이동하기 전에 해당 매장에 대한 url 얻기\n",
    "        iframe_src = iframe_element.get_attribute('src')\n",
    "        self.driver.switch_to.frame(iframe_element)\n",
    "        self.driver.find_element(By.XPATH, self.empty_entryIframe)\n",
    "\n",
    "        # 매장의 위도-경도 / 고유 ID 얻기\n",
    "        parsed_url = urlparse(iframe_src)\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        latitude = float(query_params.get('y')[0])\n",
    "        longitude = float(query_params.get('x')[0])\n",
    "\n",
    "        store_point = Point(longitude, latitude)\n",
    "        self.store_dict[\"gps\"] = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude\n",
    "        }\n",
    "\n",
    "        path_segments = parsed_url.path.split('/')\n",
    "        store_id = path_segments[2]\n",
    "        self.store_dict[\"store_id\"] = store_id\n",
    "\n",
    "        # 매장이 핫스팟에 위치해있는지 확인\n",
    "        for i in range(len(self.hotspots)):\n",
    "            polygon = self.hotspots[i][\"polygon_area\"]\n",
    "            if polygon.contains(store_point):\n",
    "                self.store_dict[\"hot_spot\"] = True  # default = False\n",
    "                break\n",
    "\n",
    "        # \"요청하신 페이지를 찾을 수 없습니다\" -> \"새로고침\" 버튼 클릭하여 매장 정보 다시 불러오기\n",
    "        try:\n",
    "            reset_elem = WebDriverWait(self.driver, 1).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"\"\"//a[contains(text(), '새로고침')]\"\"\")))\n",
    "\n",
    "            self.driver.execute_script(\"arguments[0].click()\", reset_elem)\n",
    "            print(\"새로고침 발생\")\n",
    "        except (NoSuchElementException, TimeoutException): # 매장 정보가 잘 불러와진 경우\n",
    "            pass\n",
    "\n",
    "    # 대표사진 URL 추출 함수\n",
    "    def get_image_urls(self, max_images=10, first_try=True):\n",
    "        images_xpath = \"\"\"/html/body/div[3]/div/div/div/div[6]/div[4]/div/div/div/div/a\"\"\"\n",
    "        try:\n",
    "            self.wait.until(EC.element_to_be_clickable(\n",
    "                (By.XPATH, images_xpath)))\n",
    "            images_xpath = images_xpath + \"/img\"\n",
    "            image_elements = self.driver.find_elements(By.XPATH, images_xpath)\n",
    "            image_urls = [img.get_attribute('src')\n",
    "                          for img in image_elements][:max_images]\n",
    "            return image_urls\n",
    "        except StaleElementReferenceException:\n",
    "            # 요소가 stale 상태인 경우\n",
    "            if first_try:\n",
    "                print(\"재시도\")\n",
    "                return self.get_image_urls(first_try=False)\n",
    "            else:\n",
    "                return []\n",
    "        except TimeoutException as e:\n",
    "            print(\"이미지 URL 추출 중 에러 발생: \", e)\n",
    "            if first_try:\n",
    "                self.move_to_tab(\"홈\")\n",
    "                self.move_to_tab(\"사진\")\n",
    "                return self.get_image_urls(first_try=False)\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "    # 한 매장 내에서 특정 탭으로 전환\n",
    "    ### 홈, 리뷰, 사진, 예약 등, 탭 이름을 전달해서 사용\n",
    "    def move_to_tab(self, tab_name):\n",
    "        tab_xpath = f\"\"\"//div[@role='tablist']/div/div[@class='flicking-viewport']/div[@class='flicking-camera']/a[span[text()={\n",
    "            tab_name}]]\"\"\"\n",
    "        elem = self.driver.find_element(By.XPATH, tab_xpath)\n",
    "        self.driver.execute_script(\"arguments[0].click()\", elem)\n",
    "        time.sleep(2)\n",
    "\n",
    "    # 한 매장에 대한 정보 얻기\n",
    "    def get_store_details(self):\n",
    "\n",
    "        # 매장 정보 로딩을 위한 명시적 대기\n",
    "        time.sleep(3)\n",
    "\n",
    "        # 매장 이름, 카테고리\n",
    "        try:\n",
    "            store_name_xpath = \"\"\"//*[@id=\"_title\"]/div/span\"\"\"\n",
    "            elem = self.wait.until(EC.presence_of_all_elements_located(\n",
    "                (By.XPATH, store_name_xpath)))\n",
    "\n",
    "            self.store_dict['name'] = elem[0].text\n",
    "            self.store_dict['category'] = elem[1].text\n",
    "        # 드물게 매장 이름을 크롤링하지 못하는 에러 발생\n",
    "        # 해당 매장 생략하고 다음 매장 크롤링 진행\n",
    "        except TimeoutException as e:\n",
    "            print(\"매장 이름, 카테고리 에러: \", e)\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(\"매장 이름, 카테고리 에러: \", e)\n",
    "            return False\n",
    "\n",
    "        # 신규 매장 여부\n",
    "        # 일반 크롤링일 때만 실행\n",
    "        if self.store_dict[\"new_store\"] == False:\n",
    "            try:\n",
    "                new_open_xpath = \"\"\"//*[@id='_title']/div/span[contains(text(), '새로오픈')]\"\"\"\n",
    "                new_open_spans = self.driver.find_element(\n",
    "                    By.XPATH, new_open_xpath)\n",
    "\n",
    "                if new_open_spans:\n",
    "                    self.store_dict[\"new_store\"] = True\n",
    "                else:\n",
    "                    pass\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "        # 방문자 리뷰, 블로그 리뷰 개수\n",
    "        try:\n",
    "            elem_visitor = self.driver.find_element(\n",
    "                By.XPATH, value=\"//a[contains(text(), '방문자리뷰')]\")\n",
    "            visitor_review_count = int(re.findall(\n",
    "                r'\\d+', elem_visitor.text.replace(\",\", \"\"))[0])\n",
    "            self.store_dict['visitor_review_count'] = visitor_review_count\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict['visitor_review_count'] = None\n",
    "        try:\n",
    "            elem_blog = self.driver.find_element(\n",
    "                By.XPATH, value=\"//a[contains(text(), '블로그리뷰')]\")\n",
    "            blog_review_count = int(re.findall(\n",
    "                r'\\d+', elem_blog.text.replace(\",\", \"\"))[0])\n",
    "            self.store_dict['blog_review_count'] = blog_review_count\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict['blog_review_count'] = None\n",
    "\n",
    "        # 도로명주소\n",
    "        try:\n",
    "            address_xpath = \"//strong[contains(.,'주소')]/following-sibling::div/a/span\"\n",
    "            address_elem = self.driver.find_element(By.XPATH, address_xpath)\n",
    "            address_text= address_elem.text\n",
    "            if address_text != \"\":\n",
    "                self.store_dict[\"address\"] = address_text\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict[\"address\"] = None\n",
    "        except Exception as e:\n",
    "            print(\"도로명주소 에러: \", e)\n",
    "            self.store_dict[\"address\"] = False\n",
    "\n",
    "        # 매장 전화번호\n",
    "        try:\n",
    "            phone_xpath = \"//strong[contains(.,'전화번호')]/following-sibling::div/span\"    \n",
    "            phone_elem = self.driver.find_element(By.XPATH, phone_xpath)\n",
    "            phone_text = phone_elem.text\n",
    "            if phone_text != \"\":\n",
    "                self.store_dict[\"phone\"] = phone_text\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict[\"phone\"] = None\n",
    "        except Exception as e:\n",
    "            print(\"전화번호 에러: \", e)\n",
    "            self.store_dict[\"phone\"] = False\n",
    "\n",
    "        # 인스타그램 계정 존재 확인\n",
    "        try:\n",
    "            elem = self.driver.find_element(\n",
    "                By.XPATH, value=\"//a[contains(@href, 'instagram.com')]\")\n",
    "            instagram_url = elem.get_attribute('href')\n",
    "\n",
    "            wrong_url = [\"https://instagram.com\", \"https://instagram.com/\", \"http://instagram.com\",\n",
    "                         \"http://instagram.com/\", \"instagram.com\", \"instagram.com/\",\n",
    "                         \"https://www.instagram.com/\", \"http://www.instagram.com/\", \"https://www.instagram.com\",\n",
    "                         \"http://www.instagram.com\"]\n",
    "            if instagram_url in wrong_url:\n",
    "                self.store_dict['instagram_link'] = None\n",
    "            else:\n",
    "                # query parameter 제거\n",
    "                if \"?\" in instagram_url:\n",
    "                    instagram_url = instagram_url.split(\"?\")[0]\n",
    "                # 계정 이름 이후 \"/\" 뒷부분 모두 제거\n",
    "                if instagram_url.count(\"/\") >= 4:\n",
    "                    instagram_url = \"/\".join(instagram_url.split(\"/\", 4)[:4])\n",
    "\n",
    "                self.store_dict['instagram_link'] = instagram_url\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            self.store_dict['instagram_link'] = None\n",
    "            self.store_dict['instagram_post'] = None\n",
    "            self.store_dict['instagram_follower'] = None\n",
    "        except Exception as e:\n",
    "            print(\"인스타그램 에러:\", e)\n",
    "            self.store_dict['instagram_link'] = None\n",
    "            self.store_dict['instagram_post'] = None\n",
    "            self.store_dict['instagram_follower'] = None\n",
    "\n",
    "        # 서울 미쉐린 가이드 등재 여부\n",
    "        try:\n",
    "            michelin_xpath = \"\"\"//div[a[contains(text(), '미쉐린 가이드 서울')]]\"\"\"\n",
    "            self.driver.find_element(By.XPATH, michelin_xpath)\n",
    "            self.store_dict['seoul_michelin'] = True\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict['seoul_michelin'] = False\n",
    "        except Exception as e:\n",
    "            print(\"서울 미쉐린 가이드 에러:\", e)\n",
    "            self.store_dict['seoul_michelin'] = None\n",
    "\n",
    "        # 지하철역 출구로부터 거리\n",
    "        try:\n",
    "            subway_xpath = \"/html/body/div[3]/div/div/div/div[5]/div/div[2]/div[1]/div/div[1]/div/div\"\n",
    "            elem = self.driver.find_element(By.XPATH, subway_xpath)\n",
    "            text = elem.text\n",
    "\n",
    "            numbers = re.findall(r'\\d+', text)\n",
    "            if numbers:\n",
    "                self.store_dict[\"distance_from_subway\"] = numbers[-1]\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict[\"distance_from_subway\"] = None\n",
    "        except Exception as e:\n",
    "            print(\"지하철역 에러: \", e)\n",
    "            self.store_dict[\"distance_from_subway\"] = None\n",
    "\n",
    "        # 방송 출연 여부\n",
    "        try:\n",
    "            tv_xpath = \"\"\"//strong[descendant::span[text()='TV방송정보']]\"\"\"\n",
    "            self.driver.find_element(By.XPATH, tv_xpath)\n",
    "            self.store_dict['on_tv'] = True\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict['on_tv'] = False\n",
    "        except Exception as e:\n",
    "            print(\"방송 출연 에러: \", e)\n",
    "            self.store_dict['on_tv'] = None\n",
    "\n",
    "        # 주차 가능, 반려동물 동반, 노키즈존\n",
    "        try:\n",
    "            convenient_xpath = \"//strong[descendant::span[text()='편의']]/ancestor::div[1]/div/div\"\n",
    "            elem = self.driver.find_element(By.XPATH, convenient_xpath)\n",
    "            convenients = elem.text\n",
    "\n",
    "            for parking in [\"주차\", \"발렛파킹\"]:\n",
    "                if parking in convenients:\n",
    "                    self.store_dict[\"parking_available\"] = True\n",
    "                    break\n",
    "\n",
    "            if \"반려동물 동반\" in convenients:\n",
    "                self.store_dict[\"pet_available\"] = True\n",
    "\n",
    "            if \"노키즈존\" in convenients:\n",
    "                self.store_dict[\"no_kids\"] = True\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict[\"parking_available\"] = False\n",
    "            self.store_dict[\"no_kids\"] = False\n",
    "            self.store_dict[\"pet_available\"] = False\n",
    "        except Exception as e:\n",
    "            print(\"주차, 반려동물, 노키즈 에러: \", e)\n",
    "            self.store_dict[\"parking_available\"] = False\n",
    "            self.store_dict[\"no_kids\"] = False\n",
    "            self.store_dict[\"pet_available\"] = False\n",
    "\n",
    "        # DataLab: 연령별 / 성별 검색 인기도\n",
    "        try:\n",
    "            # entryIframe 스크롤 끝까지 내려서 모든 컨텐츠 로딩\n",
    "            last_height = self.driver.execute_script(\n",
    "                \"return document.body.scrollHeight\")\n",
    "            while True:\n",
    "                self.driver.execute_script(\n",
    "                    \"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(0.5)\n",
    "                new_height = self.driver.execute_script(\n",
    "                    \"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            # DataLab 항목 찾고 해당 element로 스크롤 이동\n",
    "            datalab_xpath = \"\"\"//div[h2/span[contains(text(), '데이터랩')]]\"\"\"\n",
    "            datalab_elem = self.driver.find_element(By.XPATH, datalab_xpath)\n",
    "            self.driver.execute_script(\n",
    "                \"arguments[0].scrollIntoView(true);\", datalab_elem)\n",
    "\n",
    "            # \"테마키워드\"라는 text가 있는 경우, \"더보기 버튼을 눌러줘야 연령별/성별 검색어 비율 확인 가능\n",
    "            try:\n",
    "                theme_keyword_xpath = \"\"\".//div/div/div/h3[contains(text(), '테마키워드')]\"\"\"\n",
    "                datalab_elem.find_element(By.XPATH, theme_keyword_xpath)\n",
    "                button_elem = datalab_elem.find_element(\n",
    "                    By.XPATH, \".//div[2]/div/a\")\n",
    "                self.driver.execute_script(\"arguments[0].click()\", button_elem)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(\"데이터랩 더보기 버튼 에러: \", e)\n",
    "\n",
    "            # 20대와 30대가 top 1, 2를 차지하는지 확인\n",
    "            age_xpath = \"\"\"//*[@id=\"bar_chart_container\"]/ul/li/div[1]/span/span[1]\"\"\"\n",
    "            age_elements = self.wait.until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, age_xpath)))\n",
    "            percentage_by_age = [\n",
    "                round(float(item.text.replace('%', '')), 2) for item in age_elements]\n",
    "            top_two = sorted(percentage_by_age, reverse=True)[:2]\n",
    "            is_2030_in_top_two = percentage_by_age[1] in top_two and percentage_by_age[2] in top_two\n",
    "            if is_2030_in_top_two:\n",
    "                self.store_dict[\"age-2030\"] = True\n",
    "            else:\n",
    "                self.store_dict[\"age-2030\"] = False\n",
    "\n",
    "            # 남성의 비율이 50%를 넘는지 확인\n",
    "            gender_xpath = \"\"\"//*[@id=\"pie_chart_container\"]/div/*[local-name()='svg']/*[local-name()='g'][1]/*[local-name()='g'][3]/*[local-name()='g'][4]/*[local-name()='g']/*[local-name()='text'][2]\"\"\"\n",
    "            gender_elements = self.wait.until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, gender_xpath)))\n",
    "            female, male = [round(float(item.text.replace(\"%\", \"\")), 0)\n",
    "                            for item in gender_elements]\n",
    "            if male > 50:\n",
    "                self.store_dict[\"gender-balance\"] = False\n",
    "            else:\n",
    "                self.store_dict[\"gender-balance\"] = True\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict[\"age-2030\"] = None\n",
    "            self.store_dict[\"gender-balance\"] = None\n",
    "        except Exception as e:\n",
    "            print(\"데이터랩 에러: \", e)\n",
    "            self.store_dict[\"age-2030\"] = None\n",
    "            self.store_dict[\"gender-balance\"] = None\n",
    "\n",
    "        # 블루 리본 등재 여부 -> \"맛집\" 키워드일 경우에만 확인\n",
    "        if self.is_food == True:\n",
    "            if self.store_dict[\"name\"].replace(\" \", \"\") in [name.replace(\" \", \"\") for name in self.blue_ribbon[\"name\"].values]:\n",
    "                indices = self.blue_ribbon.index[self.blue_ribbon[\"name\"] == self.store_dict[\"name\"].replace(\" \", \"\")].tolist()\n",
    "\n",
    "                for i, index in enumerate(indices):\n",
    "                    # 1. 도로명 주소 비교\n",
    "                    # - 띄어쓰기 모두 제거한 상태로 비교\n",
    "                    address1 = self.store_dict[\"address\"].replace(\" \", \"\")\n",
    "                    address2 = self.blue_ribbon[\"address\"][index].replace(\n",
    "                        \" \", \"\")\n",
    "\n",
    "                    if address1 == address2:\n",
    "                        print(\"도로명 주소 일치!!\")\n",
    "                        self.store_dict[\"on_blue_ribbon\"] = True\n",
    "                        break\n",
    "                    # 2. 위도-경도 비교\n",
    "                    lat1 = float(self.store_dict[\"gps\"][\"latitude\"])\n",
    "                    lon1 = float(self.store_dict[\"gps\"][\"longitude\"])\n",
    "\n",
    "                    lat2 = float(self.blue_ribbon[\"latitude\"][index])\n",
    "                    lon2 = float(self.blue_ribbon[\"longitude\"][index])\n",
    "                    distance = haversine(lat1, lon1, lat2, lon2)\n",
    "                    if distance <= 50:\n",
    "                        print(\"위도-경도 근사!!\")\n",
    "                        self.store_dict[\"on_blue_ribbon\"] = True\n",
    "                        break\n",
    "                    if i + 1 == len(indices):\n",
    "                        print(\"이름만 같았던 매장\")\n",
    "                        self.store_dict[\"on_blue_ribbon\"] = False\n",
    "                        break\n",
    "            elif self.store_dict[\"phone\"] in [phone for phone in self.blue_ribbon[\"phone\"].values]:\n",
    "                print(\"있다!! 전화번호 있다!! 블루리본에 전화번호 있다!!!!\")\n",
    "                self.store_dict[\"on_blue_ribbon\"] = True    \n",
    "            else:\n",
    "                self.store_dict[\"on_blue_ribbon\"] = False\n",
    "\n",
    "        # 대표사진 크롤링\n",
    "        try:\n",
    "            imgtab_xpath = \"//a[.//span[contains(text(),'사진')]]\"\n",
    "            elem = self.driver.find_element(By.XPATH, imgtab_xpath)\n",
    "            self.driver.execute_script(\"arguments[0].click()\", elem)\n",
    "            time.sleep(2)  # 사진 로딩 대기\n",
    "\n",
    "            self.store_dict[\"image_urls\"] = self.get_image_urls()\n",
    "        except NoSuchElementException as e:  # 사진 탭이 없는 경우\n",
    "            print(\"사진 탭 없음\")\n",
    "            self.store_dict[\"image_urls\"] = []\n",
    "\n",
    "        # 인스타그램 크롤링(게시글 수, 팔로워 수)\n",
    "        if self.store_dict['instagram_link'] != None:  # 인스타그램 계정이 있는 경우에만 실행\n",
    "            try:\n",
    "                instagram_embed_url = self.store_dict['instagram_link'] + \"/embed\"\n",
    "\n",
    "                # 인스타그랩 탭으로 이동\n",
    "                self.driver.switch_to.window(self.driver.window_handles[1])\n",
    "                self.driver.get(instagram_embed_url)\n",
    "\n",
    "                xpath = \"\"\"//span[contains(., '팔로워') and contains(., '게시물')]/span/span\"\"\"\n",
    "                elements = self.wait.until(\n",
    "                    EC.presence_of_all_elements_located((By.XPATH, xpath)))\n",
    "\n",
    "                follower = elements[0].text\n",
    "                post = elements[1].text\n",
    "                self.store_dict[\"instagram_follower\"] = follower\n",
    "                self.store_dict[\"instagram_post\"] = post\n",
    "            except (NoSuchElementException, TimeoutException):\n",
    "                self.store_dict['instagram_link'] = None\n",
    "                self.store_dict[\"instagram_follower\"] = None\n",
    "                self.store_dict[\"instagram_post\"] = None\n",
    "\n",
    "            # 네이버지도 탭으로 복귀\n",
    "            self.driver.switch_to.window(self.driver.window_handles[0])\n",
    "\n",
    "        # 한 매장에 대한 크롤링 결과\n",
    "        print(self.store_dict)\n",
    "        return True\n",
    "\n",
    "    # 한 매장에 대한 크롤링 정볼르 DataFrame에 Insertion\n",
    "    def insert_into_dataframe(self):\n",
    "        new_data = pd.DataFrame([self.store_dict])\n",
    "        self.data = pd.concat([self.data, new_data], ignore_index=True)\n",
    "\n",
    "    # 한 페이지 크롤링\n",
    "    def crawling_one_page(self):\n",
    "        self.move_to_search_iframe()\n",
    "        store_count = self.scroll_to_end()\n",
    "\n",
    "        for i in range(1, store_count + 1):\n",
    "            print(f\"==== {i} 번째 매장 ====\")\n",
    "            self.get_into_store(index=i)\n",
    "            if self.get_store_details():\n",
    "                self.insert_into_dataframe()\n",
    "\n",
    "    # 한 페이지에 대한 매장 개수 반환\n",
    "    def scroll_to_end(self):\n",
    "        li_xpath = \"\"\"//*[@id=\"_pcmap_list_scroll_container\"]/ul/li\"\"\"\n",
    "        store_elements = self.wait.until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, li_xpath)))\n",
    "        store_count = len(store_elements)\n",
    "        self.driver.execute_script(\n",
    "            \"arguments[0].scrollIntoView(true);\", store_elements[-1])\n",
    "        while True:\n",
    "            time.sleep(0.5)\n",
    "            store_elements = self.wait.until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, li_xpath)))\n",
    "            new_store_count = len(store_elements)\n",
    "\n",
    "            if store_count == new_store_count:\n",
    "                break\n",
    "            store_count = new_store_count\n",
    "            self.driver.execute_script(\n",
    "                \"arguments[0].scrollIntoView(true);\", store_elements[-1])\n",
    "        return store_count\n",
    "\n",
    "    # searchIframe으로 이동\n",
    "    def move_to_search_iframe(self):\n",
    "        self.driver.switch_to.default_content()\n",
    "        self.wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, self.empty_root)))\n",
    "        self.wait.until(EC.frame_to_be_available_and_switch_to_it(\n",
    "            (By.XPATH, self.search_iframe)))\n",
    "        self.wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, self.empty_searchIframe)))\n",
    "\n",
    "    # 다음 페이지로 이동\n",
    "    def move_to_next_page(self):\n",
    "        self.driver.switch_to.default_content()\n",
    "        self.wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, self.empty_root)))\n",
    "        self.wait.until(EC.frame_to_be_available_and_switch_to_it(\n",
    "            (By.XPATH, self.search_iframe)))\n",
    "\n",
    "        nextpage_xpath = \"\"\"//a[span[contains(text(),'다음페이지')]]\"\"\"\n",
    "        next_page_button = self.wait.until(\n",
    "            EC.presence_of_element_located((By.XPATH, nextpage_xpath)))\n",
    "\n",
    "        # 다음페이지 존재 여부 확인\n",
    "        aria_disabled = next_page_button.get_attribute(\"aria-disabled\")\n",
    "        if aria_disabled == \"true\":\n",
    "            return False\n",
    "        else:\n",
    "            next_page_button.click()\n",
    "            time.sleep(2)\n",
    "            return True\n",
    "\n",
    "    def crawling(self):\n",
    "\n",
    "        self.search_keyword()\n",
    "        if self.crawl_new:\n",
    "            self.click_new_option()\n",
    "        for page in range(1, 7):\n",
    "            print(\"=\"*10+f\"page {page}\" + \"=\"*10)\n",
    "            self.crawling_one_page()\n",
    "            print(self.data)\n",
    "            # 마지막 페이지인 경우\n",
    "            if self.move_to_next_page() == False:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        self.driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    keywords = [\"맛집\", \"공방\", \"만화카페\", \"스튜디오\", \"연극\", \"동물카페\"]\n",
    "\n",
    "    location = \"가로수길\"\n",
    "    keyword = \"맛집\"\n",
    "\n",
    "    search_word = location + \" \" + keyword\n",
    "    seoul_hotspots = load_hotspots('seoul_hotspots.csv')\n",
    "\n",
    "    print(search_word, \" 크롤링 시작\")\n",
    "\n",
    "    # 음식 크롤링 여부\n",
    "    is_food = False\n",
    "    blue_ribbon_data = None\n",
    "    if keyword == \"맛집\":\n",
    "        is_food = True\n",
    "        bluer_data = load_bluer(\"서울 강남_bluer.csv\")\n",
    "        \n",
    "\n",
    "    crawler = DatePopCrawler(location=location, keyword=keyword, hotspots=seoul_hotspots,\n",
    "                             is_food=is_food, crawl_new=False, blue_ribbon=bluer_data)\n",
    "    crawler.crawling()\n",
    "    crawler_data_unique = crawler.data.drop_duplicates(\n",
    "        subset='store_id', keep='first')\n",
    "\n",
    "    if keyword == \"맛집\":\n",
    "\n",
    "        print(\"Start to crawl new stores\")\n",
    "        # 동일 검색어로 신규오픈 매장 크롤링\n",
    "        crawler_new = DatePopCrawler(location=location, keyword=keyword, hotspots=seoul_hotspots,\n",
    "                                     is_food=is_food, crawl_new=True, blue_ribbon=blue_ribbon_data)\n",
    "        crawler_new.crawling()\n",
    "        crawler_new_data_unique = crawler_new.data.drop_duplicates(\n",
    "            subset='store_id', keep='first')\n",
    "    print(f\"Crawling for {location} {keyword} is done.\")\n",
    "\n",
    "    if keyword == \"맛집\":\n",
    "        merged_data = pd.merge(crawler_data_unique, crawler_new_data_unique,\n",
    "                               on='store_id', how='outer', suffixes=('', '_new'))\n",
    "    else:\n",
    "        merged_data = crawler_data_unique\n",
    "\n",
    "    print(f\"merge하고 중복 제거 후 개수: {len(merged_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry (eagle-eye)",
   "language": "python",
   "name": "eagle-eye"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
