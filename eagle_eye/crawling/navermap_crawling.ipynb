{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import re\n",
    "\n",
    "from blueribbon_crawling import BlueRibbonCrawler\n",
    "from instagram_crawling import InstagramCrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatePopCrawler:\n",
    "    def __init__(self, location, keyword):\n",
    "        self.location = location\n",
    "        self.keyword = keyword\n",
    "        self.search_word = location + \" \" + keyword\n",
    "\n",
    "        self.is_food = False\n",
    "\n",
    "        self.data = pd.DataFrame(columns=['name', 'category', 'is_food', 'instagram_link', 'instagram_post', 'instagram_follower', 'visitor_review_count', \n",
    "                           'blog_review_count', 'distance_from_subway', 'on_tv','parking_available' , 'no_kids', 'pet_available', 'seoul_michelin',\n",
    "                           'age-2030', 'gender-balance', 'on_blue_ribbon', 'image_urls'])\n",
    "        self.empty_searchIframe = \"\"\"//*[@id=\"_pcmap_list_scroll_container\"]\"\"\"\n",
    "        self.empty_entryIframe = \"\"\"//*[@id=\"app-root\"]\"\"\"\n",
    "        self.empty_root = \"\"\"//*[@id=\"root\"]\"\"\"\n",
    "\n",
    "        self.search_iframe = \"\"\"//*[@id=\"searchIframe\"]\"\"\"\n",
    "        self.entry_iframe = \"\"\"//*[@id=\"entryIframe\"]\"\"\"\n",
    "\n",
    "        self.store_dict = {\n",
    "            'name': \"\",\n",
    "            'category': \"\",\n",
    "            'is_food': False,\n",
    "            \"instagram_link\": None,\n",
    "            \"instagram_post\": None,\n",
    "            \"instagram_follower\": None,\n",
    "            \"visitor_review_count\": 0,\n",
    "            \"blog_review_count\": 0,\n",
    "            \"distance_from_subway\": None,\n",
    "            \"on_tv\": False,\n",
    "            \"parking_available\": False,\n",
    "            \"no_kids\": False,\n",
    "            \"pet_available\": False,\n",
    "            \"seoul_michelin\": False,\n",
    "            \"age-2030\" : None,\n",
    "            \"gender-balance\": None,\n",
    "            \"on_blue_ribbon\": None,\n",
    "            \"image_urls\": [],\n",
    "        }\n",
    "\n",
    "        if keyword == \"맛집\":\n",
    "            self.blue_ribbon_crawler = BlueRibbonCrawler(self.location)\n",
    "            self.is_food = True\n",
    "            self.blue_ribbon_crawler.crawling()\n",
    "\n",
    "        self.driver = self.initialize_driver()\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "\n",
    "    def initialize_driver(self):\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"--enable-logging\")\n",
    "        options.add_argument(\"--v=1\")  # 로그 레벨 설정\n",
    "\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(\"https://map.naver.com/\")\n",
    "\n",
    "        driver.execute_script(\"window.open('');\")\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        return driver\n",
    "    \n",
    "    def initialize_dictionary(self):\n",
    "        self.store_dict = {\n",
    "            \"name\": \"\",\n",
    "            \"category\": \"\",\n",
    "            \"is_food\": self.is_food,\n",
    "            \"instagram_link\": None,\n",
    "            \"instagram_post\": None,\n",
    "            \"instagram_follower\": None,\n",
    "            \"visitor_review_count\": 0,\n",
    "            \"blog_review_count\": 0,\n",
    "            \"distance_from_subway\": None,\n",
    "            \"on_tv\": False,\n",
    "            \"parking_available\": False,\n",
    "            \"no_kids\": False,\n",
    "            \"pet_available\": False,\n",
    "            \"seoul_michelin\": False,\n",
    "            \"age-2030\" : None,\n",
    "            \"gender-balance\": None,\n",
    "            \"on_blue_ribbon\": None,\n",
    "            \"image_urls\": [],\n",
    "        }\n",
    "    \n",
    "    def search_keyword(self):\n",
    "        self.wait.until(EC.presence_of_element_located((By.XPATH, self.empty_root)))\n",
    "\n",
    "        css_selector = \".input_search\"\n",
    "        elem = self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, css_selector)))\n",
    "\n",
    "        elem.send_keys(self.search_word)\n",
    "        time.sleep(1)\n",
    "        elem.send_keys(Keys.RETURN)\n",
    "\n",
    "    def get_into_store(self, i):\n",
    "        self.driver.switch_to.default_content()\n",
    "        self.wait.until(EC.presence_of_element_located((By.XPATH, self.empty_root)))\n",
    "        self.wait.until(EC.frame_to_be_available_and_switch_to_it((By.XPATH, self.search_iframe)))\n",
    "        self.wait.until(EC.presence_of_element_located((By.XPATH, self.empty_searchIframe)))\n",
    "\n",
    "        store_xpath = f\"\"\"//*[@id=\"_pcmap_list_scroll_container\"]/ul/li[{i}]/div[1]/a[1]\"\"\"\n",
    "        elem = self.wait.until(EC.element_to_be_clickable((By.XPATH, store_xpath)))\n",
    "        time.sleep(2)\n",
    "        if i!=1:\n",
    "            self.driver.execute_script(\"arguments[0].scrollIntoView(true);\", elem)\n",
    "        self.driver.execute_script(\"arguments[0].click()\", elem)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        self.driver.switch_to.default_content()\n",
    "        self.wait.until(EC.presence_of_element_located((By.XPATH, self.empty_root)))\n",
    "        self.driver.find_element(By.XPATH, self.empty_root)\n",
    "\n",
    "        self.wait.until(EC.frame_to_be_available_and_switch_to_it((By.XPATH, self.entry_iframe)))\n",
    "        self.driver.find_element(By.XPATH, self.empty_entryIframe)\n",
    "\n",
    "        # 매장 클릭 시 \"요청하신 페이지를 찾을 수 없습니다\"라는 메시지를 갖는 에러 가끔 발생\n",
    "        # \"새로고침\" 버튼 클릭하여 매장 정보 다시 불러오기\n",
    "        try:\n",
    "            WebDriverWait(self.driver, 1).until(EC.presence_of_element_located((By.XPATH, \"//div[contains(text(), '요청하신 페이지를 찾을 수 없습니다.')]\")))\n",
    "            reset_xpath = \"\"\"//a[contains(text(), \"새로고침)]\"\"\"\n",
    "\n",
    "            reset_elem = self.wait.until(EC.presence_of_element_located((By.XPATH, reset_xpath)))\n",
    "            self.driver.execute_script(\"arguments[0].click()\", reset_elem)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def get_store_details(self):\n",
    "        self.initialize_dictionary()\n",
    "        time.sleep(3)\n",
    "\n",
    "        # 매장 이름, 카테고리\n",
    "        try:\n",
    "            store_name_xpath = \"\"\"//*[@id=\"_title\"]/div/span\"\"\"\n",
    "            elem = self.wait.until(EC.presence_of_all_elements_located((By.XPATH, store_name_xpath)))\n",
    "\n",
    "            self.store_dict['name'] = elem[0].text\n",
    "            self.store_dict['category'] = elem[1].text\n",
    "        except Exception as e:\n",
    "            print(\"매장 이름, 카테고리 에러: \", e)\n",
    "            # 희귀하게 매장 이름을 크롤링하지 못하는 에러 발생\n",
    "            # 해당 매장 생략하고 다음 매장 크롤링 진행\n",
    "            return False\n",
    "\n",
    "        # 방문자 리뷰, 블로그 리뷰 개수\n",
    "        try:\n",
    "            elem_visitor = self.driver.find_element(By.XPATH, value=\"//a[contains(text(), '방문자리뷰')]\")\n",
    "            elem_blog = self.driver.find_element(By.XPATH, value=\"//a[contains(text(), '블로그리뷰')]\")\n",
    "\n",
    "            visitor_review_count = int(re.findall(r'\\d+', elem_visitor.text.replace(\",\", \"\"))[0])\n",
    "            blog_review_count = int(re.findall(r'\\d+', elem_blog.text.replace(\",\", \"\"))[0])\n",
    "\n",
    "            self.store_dict['visitor_review_count'] = visitor_review_count\n",
    "            self.store_dict['blog_review_count'] = blog_review_count\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict['visitor_review_count'] = None\n",
    "            self.store_dict['blog_review_count'] = None\n",
    "\n",
    "        # 인스타그램 계정 존재 확인\n",
    "        try:\n",
    "            elem = self.driver.find_element(By.XPATH, value= \"//a[contains(text(), '인스타그램')]\")\n",
    "            instagram_url = elem.get_attribute('href')\n",
    "\n",
    "            # 인스타그램 계정 url 뒤에 queryParameter가 붙은 경우 or \"/\"가 하나 더 붙은 경우\n",
    "            # 두 경우 모두, 해당 url에 \"/embed\"를 concatenation하면 응답으로 \"알 수 없는 페이지\"\n",
    "            # 때문에 url에서 해당 인스타그램 계정의 이름에 해당하는 부분 이후는 제거\n",
    "            if instagram_url == \"https://instagram.com\" or \"https://instagram.com/\" or instagram_url == \"http://instagram.com\" or instagram_url == \"http://instagram.com/\":\n",
    "                self.store_dict['instagram_link'] = None\n",
    "            else:\n",
    "                if \"?\" in instagram_url:\n",
    "                    instagram_url = instagram_url.split(\"?\")[0]\n",
    "\n",
    "                if instagram_url.count(\"/\") >= 4:\n",
    "                    instagram_url = \"/\".join(instagram_url.split(\"/\", 4)[:4])\n",
    "\n",
    "                self.store_dict['instagram_link'] = instagram_url\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict['instagram_link'] = None\n",
    "            self.store_dict['instagram_post'] = None\n",
    "            self.store_dict['instagram_follower'] = None\n",
    "        except Exception as e:\n",
    "            print(\"인스타그램 에러:\", e)\n",
    "            self.store_dict['instagram_link'] = None\n",
    "            self.store_dict['instagram_post'] = None\n",
    "            self.store_dict['instagram_follower'] = None\n",
    "\n",
    "        # 서울 미쉐린 가이드\n",
    "        try:\n",
    "            michelin_xpath = \"\"\"//div[a[contains(text(), '미쉐린 가이드 서울')]]\"\"\"\n",
    "            self.driver.find_element(By.XPATH, michelin_xpath)\n",
    "            self.store_dict['seoul_michelin'] = True\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict['seoul_michelin'] = False\n",
    "        except Exception as e:\n",
    "            print(\"서울 미쉐린 가이드 에러:\", e)\n",
    "            self.store_dict['seoul_michelin'] = None\n",
    "            \n",
    "        # 지하철역 출구로부터 거리\n",
    "        try:\n",
    "            subway_xpath = \"/html/body/div[3]/div/div/div/div[5]/div/div[2]/div[1]/div/div[1]/div/div\"\n",
    "            elem = self.driver.find_element(By.XPATH, subway_xpath)\n",
    "            text = elem.text\n",
    "\n",
    "            numbers = re.findall(r'\\d+', text)\n",
    "            if numbers:\n",
    "                self.store_dict[\"distance_from_subway\"] = numbers[-1]\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict[\"distance_from_subway\"] = None\n",
    "        except Exception as e:\n",
    "            print(\"지하철역 에러: \", e)\n",
    "            self.store_dict[\"distance_from_subway\"] = None\n",
    "\n",
    "        # 방송 출연 여부\n",
    "        try:\n",
    "            tv_xpath =  \"\"\"//strong[descendant::span[text()='TV방송정보']]\"\"\"\n",
    "            self.driver.find_element(By.XPATH, tv_xpath)\n",
    "            self.store_dict['on_tv'] = True\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict['on_tv'] = False\n",
    "        except Exception as e:\n",
    "            print(\"방송 출연 에러: \", e)\n",
    "            self.store_dict['on_tv'] = None\n",
    "\n",
    "        # 주차 가능, 반려동물 동반, 노키즈존\n",
    "        try:\n",
    "            convenient_xpath = \"//strong[descendant::span[text()='편의']]/ancestor::div[1]/div/div\"\n",
    "            elem = self.driver.find_element(By.XPATH, convenient_xpath)\n",
    "            convenients = elem.text\n",
    "\n",
    "            for parking in [\"주차\", \"발렛파킹\"]:\n",
    "                if parking in convenients:\n",
    "                    self.store_dict[\"parking_available\"] = True\n",
    "                    break\n",
    "\n",
    "            if \"반려동물 동반\" in convenients:\n",
    "                self.store_dict[\"pet_available\"] = True\n",
    "\n",
    "            if \"노키즈존\" in convenients:\n",
    "                self.store_dict[\"no_kids\"] = True\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict[\"parking_available\"] = False\n",
    "            self.store_dict[\"no_kids\"] = False\n",
    "            self.store_dict[\"pet_available\"] = False\n",
    "        except Exception as e:\n",
    "            print(\"주차, 반려동물, 노키즈 에러: \", e)\n",
    "            self.store_dict[\"parking_available\"] = False\n",
    "            self.store_dict[\"no_kids\"] = False\n",
    "            self.store_dict[\"pet_available\"] = False\n",
    "\n",
    "        # DataLab: 연령별 / 성별 검색 인기도\n",
    "        try:\n",
    "            # entryIframe 스크롤 끝까지 내려서 모든 컨텐츠 로딩\n",
    "            last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            while True:\n",
    "                self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(0.5)\n",
    "                new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            # DataLab 항목 찾고 해당 element로 스크롤 이동\n",
    "            datalab_xpath = \"\"\"//div[h2/span[contains(text(), '데이터랩')]]\"\"\"\n",
    "            datalab_elem = self.driver.find_element(By.XPATH, datalab_xpath)\n",
    "            self.driver.execute_script(\"arguments[0].scrollIntoView(true);\", datalab_elem)\n",
    "\n",
    "            # \"테마키워드\"라는 text가 있는 경우, \"더보기 버튼을 눌러줘야 연령별/성별 검색어 비율 확인 가능\n",
    "            try:\n",
    "                theme_keyword_xpath = \"\"\".//div/div/div/h3[contains(text(), '테마키워드')]\"\"\"\n",
    "                datalab_elem.find_element(By.XPATH, theme_keyword_xpath)\n",
    "                button_elem = datalab_elem.find_element(By.XPATH, \".//div[2]/div/a\")\n",
    "                self.driver.execute_script(\"arguments[0].click()\", button_elem)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(\"데이터랩 더보기 버튼 에러: \", e)\n",
    "            \n",
    "            # 20대와 30대가 top 1, 2를 차지하는지 확인\n",
    "            age_xpath = \"\"\"//*[@id=\"bar_chart_container\"]/ul/li/div[1]/span/span[1]\"\"\"\n",
    "            age_elements = self.wait.until(EC.presence_of_all_elements_located((By.XPATH, age_xpath)))\n",
    "            percentage_by_age = [round(float(item.text.replace('%', '')), 2) for item in age_elements]\n",
    "            top_two = sorted(percentage_by_age, reverse=True)[:2]\n",
    "            is_2030_in_top_two = percentage_by_age[1] in top_two and percentage_by_age[2] in top_two\n",
    "            if is_2030_in_top_two:\n",
    "                self.store_dict[\"age-2030\"] = True\n",
    "            else:\n",
    "                self.store_dict[\"age-2030\"] = False\n",
    "\n",
    "            # 남성의 비율이 50%를 넘는지 확인\n",
    "            gender_xpath = \"\"\"//*[@id=\"pie_chart_container\"]/div/*[local-name()='svg']/*[local-name()='g'][1]/*[local-name()='g'][3]/*[local-name()='g'][4]/*[local-name()='g']/*[local-name()='text'][2]\"\"\"\n",
    "            gender_elements = self.wait.until(EC.presence_of_all_elements_located((By.XPATH, gender_xpath)))\n",
    "            female, male = [round(float(item.text.replace(\"%\", \"\")), 0) for item in gender_elements]\n",
    "            if male > 50:\n",
    "                self.store_dict[\"gender-balance\"] = False\n",
    "            else:\n",
    "                self.store_dict[\"gender-balance\"] = True\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict[\"age-2030\"] = None\n",
    "            self.store_dict[\"gender-balance\"] = None\n",
    "        except Exception as e:\n",
    "            print(\"데이터랩 에러: \", e)\n",
    "            self.store_dict[\"age-2030\"] = None\n",
    "            self.store_dict[\"gender-balance\"] = None\n",
    "\n",
    "        # 블루 리본 등재 여부 -> \"맛집\" 키워드일 경우에만 확인\n",
    "        if self.is_food == True:\n",
    "            if self.store_dict[\"name\"] in self.blue_ribbon_crawler.data[\"name\"].values:\n",
    "                self.store_dict[\"on_blue_ribbon\"] = True\n",
    "            else:\n",
    "                self.store_dict[\"on_blue_ribbon\"] = False\n",
    "\n",
    "        # 대표사진 크롤링\n",
    "        try:\n",
    "            imgtab_xpath = \"//a[.//span[contains(text(),'사진')]]\"\n",
    "            elem = self.driver.find_element(By.XPATH, imgtab_xpath)\n",
    "            self.driver.execute_script(\"arguments[0].click()\", elem)\n",
    "            time.sleep(2) # 사진 로딩 대기\n",
    "\n",
    "            images_xpath = \"\"\"/html/body/div[3]/div/div/div/div[6]/div[4]/div/div/div/div/a/img\"\"\"\n",
    "            self.wait.until(EC.presence_of_all_elements_located((By.XPATH, images_xpath)))\n",
    "\n",
    "            image_elements = self.wait.until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, images_xpath))\n",
    "            )\n",
    "            image_urls = [img.get_attribute('src') for img in image_elements][:10] # 최대 10개의 이미지 url\n",
    "            self.store_dict[\"image_urls\"] = image_urls\n",
    "        except NoSuchElementException:\n",
    "            self.store_dict[\"image_urls\"] = None\n",
    "        except Exception as e:\n",
    "            print(\"대표사진 에러: \", e)\n",
    "            self.store_dict[\"image_urls\"] = None\n",
    "\n",
    "        # 인스타그램 크롤링\n",
    "        if self.store_dict['instagram_link'] != None: # 인스타그램 계정이 있는 경우에만 실행\n",
    "            try:\n",
    "                instagram_embed_url = self.store_dict['instagram_link'] + \"/embed\"\n",
    "\n",
    "                # 인스타그랩 탭으로 이동\n",
    "                self.driver.switch_to.window(self.driver.window_handles[1])\n",
    "                self.driver.get(instagram_embed_url)\n",
    "\n",
    "                # time.sleep(2)\n",
    "\n",
    "                xpath = \"\"\"//span[contains(., '팔로워') and contains(., '게시물')]/span/span\"\"\"\n",
    "                elements = self.wait.until(EC.presence_of_all_elements_located((By.XPATH, xpath)))\n",
    "\n",
    "                follower = elements[0].text\n",
    "                post = elements[1].text\n",
    "                self.store_dict[\"instagram_follower\"] = follower\n",
    "                self.store_dict[\"instagram_post\"] = post\n",
    "            except NoSuchElementException:\n",
    "                self.store_dict['instagram_link'] = None\n",
    "                self.store_dict[\"instagram_follower\"] = None\n",
    "                self.store_dict[\"instagram_post\"] = None\n",
    "            except Exception as e:\n",
    "                print(\"인스타그램 에러: \", e)\n",
    "                self.store_dict['instagram_link'] = None\n",
    "                self.store_dict[\"instagram_follower\"] = None\n",
    "                self.store_dict[\"instagram_post\"] = None\n",
    "\n",
    "            # 네이버지도 탭으로 복귀\n",
    "            self.driver.switch_to.window(self.driver.window_handles[0])\n",
    "        \n",
    "        print(self.store_dict)\n",
    "\n",
    "        return True\n",
    "\n",
    "    # 한 매장에 대한 크롤링 진행 후, 해당 정보를 DataFrame에 Insertion\n",
    "    def insert_into_dataframe(self):\n",
    "        new_data = pd.DataFrame([self.store_dict])\n",
    "        self.data = pd.concat([self.data, new_data], ignore_index=True)\n",
    "\n",
    "    # 한 페이지 크롤링\n",
    "    # 페이지별로 전체 매장 개수가 다름\n",
    "    # 첫 페이지의 경우 54개, 그 이후에는 50개\n",
    "    # 예외 케이스 있을 수 있기 때문에 유연하게 대응할 수 있도록 update 필요\n",
    "    def crawling_one_page(self):\n",
    "        self.driver.switch_to.default_content()\n",
    "        self.wait.until(EC.presence_of_element_located((By.XPATH, self.empty_root)))\n",
    "        self.wait.until(EC.frame_to_be_available_and_switch_to_it((By.XPATH, self.search_iframe)))\n",
    "        self.wait.until(EC.presence_of_element_located((By.XPATH, self.empty_searchIframe)))\n",
    "\n",
    "        li_xpath = \"\"\"//*[@id=\"_pcmap_list_scroll_container\"]/ul/li\"\"\"\n",
    "        store_elements = self.wait.until(EC.presence_of_all_elements_located((By.XPATH, li_xpath)))\n",
    "        store_count = len(store_elements)\n",
    "        self.driver.execute_script(\"arguments[0].scrollIntoView(true);\", store_elements[-1])\n",
    "        while True:\n",
    "            time.sleep(0.5)\n",
    "            store_elements = self.wait.until(EC.presence_of_all_elements_located((By.XPATH, li_xpath)))\n",
    "            new_store_count = len(store_elements)\n",
    "\n",
    "            if store_count == new_store_count:\n",
    "                break\n",
    "            store_count = new_store_count\n",
    "            self.driver.execute_script(\"arguments[0].scrollIntoView(true);\", store_elements[-1])\n",
    "            \n",
    "        for i in range(1, store_count + 1):\n",
    "            print(\"=\"*3+f\"{i} 번째 매장\"+ \"=\"*3)\n",
    "            self.get_into_store(i=i)\n",
    "            if self.get_store_details():\n",
    "                self.insert_into_dataframe()\n",
    "\n",
    "    # 다음 페이지로 이동\n",
    "    def move_to_next_page(self):\n",
    "        self.driver.switch_to.default_content()\n",
    "        self.wait.until(EC.presence_of_element_located((By.XPATH, self.empty_root)))\n",
    "        self.wait.until(EC.frame_to_be_available_and_switch_to_it((By.XPATH, self.search_iframe)))\n",
    "\n",
    "        nextpage_xpath = \"\"\"//a[span[contains(text(),'다음페이지')]]\"\"\"\n",
    "        next_page_button = self.wait.until(EC.element_to_be_clickable((By.XPATH, nextpage_xpath)))\n",
    "        next_page_button.click()\n",
    "\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling page 0......\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m keyword \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m맛집\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m search_word \u001b[38;5;241m=\u001b[39m location \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m keyword\n\u001b[0;32m----> 7\u001b[0m crawler \u001b[38;5;241m=\u001b[39m \u001b[43mDatePopCrawler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m crawler\u001b[38;5;241m.\u001b[39msearch_keyword()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m):\n",
      "Cell \u001b[0;32mIn[32], line 43\u001b[0m, in \u001b[0;36mDatePopCrawler.__init__\u001b[0;34m(self, location, keyword)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblue_ribbon_crawler \u001b[38;5;241m=\u001b[39m BlueRibbonCrawler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_food \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblue_ribbon_crawler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrawling\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize_driver()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait \u001b[38;5;241m=\u001b[39m WebDriverWait(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver, \u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/eagle-eye/eagle_eye/crawling/blueribbon_crawling.py:16\u001b[0m, in \u001b[0;36mBlueRibbonCrawler.crawling\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrawling page 0......\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrawling_onepage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_page):\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrawling page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m......\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/eagle-eye/eagle_eye/crawling/blueribbon_crawling.py:28\u001b[0m, in \u001b[0;36mBlueRibbonCrawler.crawling_onepage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcrawling_onepage\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://www.bluer.co.kr/api/v1/restaurants?page=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_page\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m&query=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_page \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_page \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotalPages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/eagle-eye-XOKA1mmI-py3.12/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/eagle-eye-XOKA1mmI-py3.12/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/eagle-eye-XOKA1mmI-py3.12/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/eagle-eye-XOKA1mmI-py3.12/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/eagle-eye-XOKA1mmI-py3.12/lib/python3.12/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/eagle-eye-XOKA1mmI-py3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/eagle-eye-XOKA1mmI-py3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/eagle-eye-XOKA1mmI-py3.12/lib/python3.12/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1419\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1419\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1420\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1253\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1252\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    location = \"정읍시\"\n",
    "    keyword = \"맛집\"\n",
    "    search_word = location + \" \" + keyword\n",
    "\n",
    "    crawler = DatePopCrawler(location=location, keyword= keyword)\n",
    "\n",
    "    crawler.search_keyword()\n",
    "    for page in range(1, 7):\n",
    "        print(\"=\"*10+f\"page {page}\"+ \"=\"*10)\n",
    "        crawler.crawling_one_page()\n",
    "        time.sleep(1)\n",
    "        crawler.move_to_next_page()\n",
    "        print(crawler.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry (eagle-eye)",
   "language": "python",
   "name": "eagle-eye"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
